{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport random\nfrom PIL import Image, ImageEnhance\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\n# Define constants\nIMAGE_SIZE = 128\ntrain_dir = '/kaggle/input/brain-tumor-mri-dataset/Training/'\ntest_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing/'\n\n# Data preparation\ntrain_paths = []\ntrain_labels = []\nfor label in os.listdir(train_dir):\n    for image in os.listdir(train_dir + label):\n        train_paths.append(train_dir + label + '/' + image)\n        train_labels.append(label)\n\ntrain_paths, train_labels = shuffle(train_paths, train_labels)\n\ntest_paths = []\ntest_labels = []\nfor label in os.listdir(test_dir):\n    for image in os.listdir(test_dir + label):\n        test_paths.append(test_dir + label + '/' + image)\n        test_labels.append(label)\n\ntest_paths, test_labels = shuffle(test_paths, test_labels)\n\n# Data Augmentation\ndef augment_image(image):\n    image = Image.fromarray(np.uint8(image))\n    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))\n    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))\n    image = np.array(image) / 255.0\n    return image\n\ndef open_images(paths, num_augmentations=2):\n    images = []\n    for path in paths:\n        original_image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n        original_image = np.array(original_image) / 255.0\n        images.append(original_image)\n        for _ in range(num_augmentations - 1):\n            augmented_image = augment_image(original_image)\n            images.append(augmented_image)\n    return np.array(images)\n\n# Model definition\ndef create_densenet_model(input_shape, num_classes):\n    base_model = keras.applications.DenseNet121(include_top=False, input_shape=input_shape)\n    base_model.trainable = True\n    model = keras.Sequential([\n        base_model,\n        GlobalAveragePooling2D(),\n        Dense(512, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    return model\n\nmodel = create_densenet_model((IMAGE_SIZE, IMAGE_SIZE, 3), len(set(train_labels)))\n\n# Model compilation with learning rate scheduling\ninitial_learning_rate = 0.001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\noptimizer = Adam(learning_rate=lr_schedule)\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Label encoding\nlabel_encoder = LabelEncoder()\ntrain_labels_encoded = label_encoder.fit_transform(train_labels)\ntest_labels_encoded = label_encoder.transform(test_labels)\n\n# Model training\nbatch_size = 32\nepochs = 30","metadata":{"execution":{"iopub.status.busy":"2024-04-30T09:00:24.816178Z","iopub.execute_input":"2024-04-30T09:00:24.816463Z","iopub.status.idle":"2024-04-30T09:00:26.886806Z","shell.execute_reply.started":"2024-04-30T09:00:24.816440Z","shell.execute_reply":"2024-04-30T09:00:26.886076Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    open_images(train_paths),\n    np.repeat(train_labels_encoded, 2),  \n    epochs=epochs,\n    batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T09:00:26.887823Z","iopub.execute_input":"2024-04-30T09:00:26.888111Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1714467802.813376      83 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m133/357\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 76ms/step - accuracy: 0.4536 - loss: 1.3466","output_type":"stream"}]},{"cell_type":"code","source":"test_images = open_images(test_paths)\ntest_loss, test_accuracy = model.evaluate(test_images, test_labels_encoded)\nprint(\"Test Accuracy:\", test_accuracy)\n\n# Classification report and confusion matrix\ny_pred = np.argmax(model.predict(test_images), axis=-1)\nprint(classification_report(test_labels_encoded, y_pred))\n\ncm = confusion_matrix(test_labels_encoded, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}